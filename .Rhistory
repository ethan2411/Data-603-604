summary(back.model.pred.only$model)
install.packages("equatiomatic")
library(equatiomatic)
install.packages('equatiomatic')
library(equatiomatic)
as.formula(
paste0("y ~ ", round(coefficients(back.model.pred.only)[1],2), "",
paste(sprintf(" %+.2f*%s ",
coefficients(back.model.pred.only)[-1],
names(coefficients(back.model.pred.only)[-1])),
collapse="")
)
)
library(broom)
library(dplyr)
get_formula <- function((back.model.pred.only) {
get_formula <- function(model) {
broom::tidy(model)[, 1:2] %>%
mutate(sign = ifelse(sign(estimate) == 1, ' + ', ' - ')) %>% #coeff signs
mutate_if(is.numeric, ~ abs(round(., 2))) %>% #for improving formatting
mutate(a = ifelse(term == '(Intercept)', paste0('y ~ ', estimate), paste0(sign, estimate, ' * ', term))) %>%
summarise(formula = paste(a, collapse = '')) %>%
as.character
}
get_formula((back.model.pred.only)
get_formula(back.model.pred.only)
newFormula = as.formula(substituteDirect(formula(back.model.pred.only), as.list(coef(back.model.pred.only ))))
newFormula = as.formula(substituteDirect(formula(back.model.pred.only), as.list(coef(back.model.pred.only))))
formula(back.model.pred.only)
knitr::opts_chunk$set(echo = TRUE)
#Using stepwise selection to find the most important variables
data_train = na.omit(data_train)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(glmnet)
library(caret)
library(Metrics)
library(DescTools)
listings = read.csv("https://raw.githubusercontent.com/ethan2411/Data-601-602/main/listings.csv")
listings_original = read.csv("https://raw.githubusercontent.com/ethan2411/Data-601-602/main/listings.csv")
head(listings_original)
head(listings)
colnames(listings)
# Converting price to be numeric, removing $ and , to make it possible
listings = listings %>%
mutate(price = as.numeric(gsub("[$,]", "", price)))
# Check the first few rows of the updated dataframe
head(listings)
ggplot(data = listings, aes(x=price, y = neighbourhood_cleansed)) + geom_violin(col="blue")+ geom_boxplot(col="purple")+labs(title = "Distribution of Price by Neighbourhood", x = "Price", y = "Neighbourhood")
# Filter out the outliers so it is easier to see the graphs
listings_filtered = listings %>%
filter(price < 1500)
# Create the plot using the filtered data
ggplot(data = listings_filtered, aes(x = price, y = neighbourhood_cleansed)) + geom_boxplot(col = "purple") +labs(title = "Distribution of Price by Neighbourhood", x = "Price", y = "Neighbourhood")
# Create the plot using the filtered data
ggplot(data = listings_filtered, aes(x = price, y = neighbourhood_cleansed)) +
geom_violin(col = "purple") +labs(title = "Distribution of Price by Neighbourhood", x = "Price ($AUD)", y = "Neighbourhood")
# Create the plot using the filtered data
ggplot(data = listings_filtered, aes(x = price, y = room_type)) +
geom_violin(col = "blue", width= 1.5)+
geom_boxplot(col = "purple", width=0.2) +
theme_minimal() +
labs(
title = "Distribution of Price by Property Type",
x = "Price",
y = "Property Type"
)
ggplot(data = listings_filtered, aes(x = price, y = room_type)) + geom_violin(col = "blue", width= 1.5)+ geom_boxplot(col = "purple", width=0.2) + labs(title = "Distribution of Price by Room Type", x = "Price ($AUD)", y = "Room Type")
ggplot(data = listings, aes(y=neighbourhood_cleansed, fill=room_type)) + ylab("Neighbourhood") + geom_bar(color="black", width = 0.8) + scale_fill_manual(values=c("plum", "purple", "blue", "navy")) + ggtitle("Distribution of Room Types per Neighbourhood") + theme_minimal()
#creating the confidence intervals and getting mean price for each neighbourhood
neighbourhood_means = listings %>%
group_by(neighbourhood_cleansed) %>%
summarize(
mean_price = mean(price, na.rm = TRUE),
lower_ci = t.test(price, conf.level = 0.95)$conf.int[1],
upper_ci = t.test(price, conf.level = 0.95)$conf.int[2]
)
head(neighbourhood_means)
ggplot(neighbourhood_means, aes(x = reorder(neighbourhood_cleansed, mean_price), y = mean_price)) +
geom_bar(stat = "identity", col = 'red', fill = 'blue', width = 0.7) +labs(title = "Neighbourhood Mean Prices", x = "Neighbourhood", y = "Mean Price ($AUD)") + coord_flip()
#plotting the confidence intervals
ggplot(neighbourhood_means, aes(x = reorder(neighbourhood_cleansed, mean_price), y = mean_price)) + geom_point() + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) + coord_flip() + labs(x = "Neighbourhood", y = "Mean Price ($AUD)", title = "Mean Price by Neighbourhood with Confidence Intervals")
#creating the confidence intervals and getting mean price for each neighbourhood
room_type_means = listings %>%
group_by(room_type) %>%
summarize(
mean_price = mean(price, na.rm = TRUE),
lower_ci = t.test(price, conf.level = 0.95)$conf.int[1],
upper_ci = t.test(price, conf.level = 0.95)$conf.int[2]
)
head(room_type_means)
ggplot(room_type_means, aes(x = reorder(room_type, mean_price), y = mean_price)) +
geom_bar(stat = "identity", col = 'red', fill = 'blue', width = 0.7) +labs(title = "Room Type Mean Prices", x = "Room Type", y = "Mean Price ($AUD)") + coord_flip()
#plotting the confidence intervals
ggplot(room_type_means, aes(x = reorder(room_type, mean_price), y = mean_price)) + geom_point() + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) + coord_flip() + labs(x = "Room Type", y = "Mean Price ($AUD)", title = "Mean Price by Room Type with Confidence Intervals")
room_type_means
#P-value is tiny. This means we reject H_0 and conclude that there is a difference in mean prices throughout the neighbourhoods
options(Scipen = 999)
neighbourhood.aov = aov(price~neighbourhood_cleansed, data = listings)
summary(neighbourhood.aov)
#This we may or may not use. its the confidence intervals for every single comparison. We can probably remove the output and just go through it and see if there are any neighbourhoods that are significantly different than all others
PostHocTest(neighbourhood.aov, method="lsd")
compare = round(cbind(
pval= PostHocTest(neighbourhood.aov, method="lsd")$neighbourhood_cleansed[,"pval"]
),6)
neighbourhood.diff = data.frame(compare)
head(neighbourhood.diff,10)
#which neighbourhoods have a significant difference and which do not
diff = subset(neighbourhood.diff, pval<0.05)
diff
nodiff = subset(neighbourhood.diff, pval >=0.05)
nodiff
#each neighbourhood is being compared to 37 other neighbourhoods
#703 total comparisons
nrow(neighbourhood.diff)
#340 have differences
nrow(diff)
#363 have no significant differences
nrow(nodiff)
# List of unique Neighbourhoods
unique_Neighbourhoods = c(
"Sydney", "Manly", "Randwick", "Waverley", "Mosman",
"Marrickville", "Warringah", "Leichhardt", "Hornsby", "Woollahra",
"Canterbury", "Sutherland Shire", "Ryde", "Ku-Ring-Gai", "Pittwater",
"North Sydney", "Willoughby", "Rockdale", "The Hills Shire", "Penrith",
"Ashfield", "Parramatta", "Lane Cove", "Hurstville", "Hunters Hill",
"Auburn", "Burwood", "Camden", "Blacktown", "Liverpool",
"City Of Kogarah", "Bankstown", "Canada Bay", "Botany Bay", "Holroyd",
"Strathfield", "Campbelltown", "Fairfield"
)
# Create an empty dataframe to store the results for each Neighbourhood
Neighbourhood_diff_df = data.frame(Neighbourhood = character(0), Different = integer(0), Same = integer(0))
# List of unique Neighbourhoods
# Loop through each Neighbourhood
for (Neighbourhood in unique_Neighbourhoods) {
# Filter the data for the Neighbourhood
filtered_data = diff[grep(paste0("-", Neighbourhood), rownames(diff)), ]
# Calculate the count of significant differences for this Neighbourhood
count_diff = length(filtered_data)
# Create a new row for the dataframe
new_row = data.frame(Neighbourhood = Neighbourhood, Statistically_significant_difference = count_diff, Not_statistically_significant_difference = 37-count_diff)
# Add the new row to the dataframe
Neighbourhood_diff_df = rbind(Neighbourhood_diff_df, new_row)
}
# Print the resulting dataframe
Neighbourhood_diff_df
plot(neighbourhood.aov, which = c(2,3))
#P-value shows there is a significant difference in mean price by room type
rooms.aov = aov(price~room_type, data = listings)
summary(rooms.aov)
#This shows exactly which rooms are different in price and which are not
PostHocTest(rooms.aov, method="lsd")
plot(rooms.aov, which = c(2,3))
# Seeing what columns have too many missing values, we will remove these
missing_values = is.na(listings)
missing_counts = colSums(missing_values)
columns5000_missing = missing_counts[missing_counts >5000]
print(columns5000_missing)
#create a feature for if a host has an about section? remove host_about
#other features too probably
#maybe how long someone has been a host will affect price?
listings$host_since = as.Date(listings$host_since)
listings$hostfor = as.numeric(difftime(Sys.Date(), listings$host_since, units = "days"))
sum(is.na(listings$hostfor))
# fill missing values in 'hostfor' with the mean
mean_hostfor = mean(listings$hostfor, na.rm = TRUE)
listings$hostfor[is.na(listings$hostfor)] = mean_hostfor
sum(is.na(listings$hostfor))
# fill missing 'beds' values with the median
# median is 2 and mean is 2.1 something
median_beds = median(listings$beds, na.rm = TRUE)
listings$beds[is.na(listings$beds)] = median_beds
#maybe if the host includes an in depth summary about themselves it will affect price?
listings$host_about_word_count = sapply(listings$host_about, function(text) {
words = unlist(strsplit(text, " "))
return(length(words))
})
#same for a description of the place?
# Extract the number of bathrooms available
# Need to find out how to also carry over decimal and "half-bath" listings
#if we can't do it maybe we just leave it as bathrooms_text
listings$bathrooms_count = as.numeric(gsub("[^0-9]", "", listings$bathrooms_text))
#Will need to remove this once the top part is figured out
listings$bathrooms_count <- ifelse(is.na(listings$bathrooms_count), 0, listings$bathrooms_count)
print(unique(listings$bathrooms_count))
print(unique(listings$bathrooms_text))
# Replace empty values with "f" so there isnt empty values
listings = listings %>%
mutate(host_is_superhost = ifelse(host_is_superhost == "", "f", host_is_superhost), host_has_profile_pic = ifelse(host_has_profile_pic == "", "f", host_has_profile_pic), host_identity_verified = ifelse(host_identity_verified == "", "f", host_identity_verified)
)
#removing columns that will definitely have nothing to do with price
listings = listings[, !(colnames(listings) %in% c("listing_url", "scrape_id", "last_scraped", "source", "picture_url", "host_id", "host_url", "host_thumbnail_url", "host_picture_url", "neighbourhood", "neighbourhood_group_cleansed", "license", "calendar_last_scraped", "calendar_updated", "property_type", "bedrooms", "host_since", "host_location", "host_about", "bathrooms_test", "bathrooms", "review_scores_communication", "review_scores_location", "review_scores_value", "reviews_per_month", "review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness", "review_scores_checkin", "host_listings_count", "host_total_listings_count", "last_review", "host_name", "calculated_host_listings_count", "calculated_host_listings_count_entire_homes", "calculated_host_listings_count_private_rooms", "calculated_host_listings_count_shared_rooms", "host_neighbourhood", "availability_30", "availability_60", "availability_90", "minimum_minimum_nights", "maximum_minimum_nights", "minimum_maximum_nights", "maximum_maximum_nights", "host_verifications", "number_of_reviews_ltm", "number_of_reviews_l30d", "host_response_time", "host_response_rate", "host_acceptance_rate", "maximum_nights", "minimum_nights", "bathrooms_text", "has_availability", "first_review"))]
#bathrooms was removed at end because only bathroom_text will be needed, will probably have to do some feature engineering for lots of these variables
listings = listings[, !(colnames(listings) %in% c("description", "neighborhood_overview", "latitude", "longitude", "name", "amenities", "id"))]
head(listings)
colnames(listings)
#head(listings$beds)
sapply(listings, function(x) length(unique(x)))
#head(listings$calculated_host_listings_count_entire_homes)
print(unique(listings$bathrooms_count))
head(listings,10)
#price is our y variable
#For x-variables we have 15 total, there are 9 numerical and 6 categorical
print(unique(listings$host_has_profile_pic))
# Split the data into training and testing sets
options(scipen = 999) # For Readability
trainIndex = createDataPartition(listings$price, p = .8,
list = FALSE,
times = 1)
data_train = listings[ trainIndex,]
data_test  = listings[-trainIndex,]
# Fit a linear regression model
set.seed(123)
linearmodel = lm(price ~ ., data = data_train)
summary.linearmodel = summary(linearmodel)
summary.linearmodel
# Make predictions on the test data
predictions = predict(linearmodel, newdata = data_test)
rmse_value1 = rmse(predictions, data_train$price)
mse_value1 = mse(predictions, data_train$price)
mae_value1 = mae(predictions, data_train$price)
rmse_value = rmse(predictions, data_test$price)
mse_value = mse(predictions, data_test$price)
mae_value = mae(predictions, data_test$price)
# Print the evaluation metrics
#The N/A's are because there are null values in bathrooms_count
cat("Training Mean Squared Error (MSE):", mse_value, "\n")
cat("Training Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Training Mean Absolute Error (MAE):", mae_value, "\n")
library(broom) #converting the summary of the linear model to a dataframe.
linearmodel.df = tidy(summary.linearmodel)
linearmodel.df
significant.linearmodel.df = filter(linearmodel.df, p.value < 0.05)
head(significant.linearmodel.df,22)
print(listings[4,])
linear.predict = predict(linearmodel, data.frame(listings[4,]), interval = 'predict')
linear.predict
#plots look alright, big upper tail on normaility plot but rest of it is fine i think
plot(linearmodel)
#Using stepwise selection to find the most important variables
data_train = na.omit(data_train)
model_stepwise = step(linearmodel, direction = "both")
predictions_step = predict(model_stepwise, newdata = data_test)
rmse_value = rmse(predictions_step, data_test$price)
mse_value = mse(predictions_step, data_test$price)
mae_value = mae(predictions_step, data_test$price)
# Print the evaluation metrics
#The N/A's are because there are null values in bathrooms_count
#Checking the model
summary(model_stepwise)
cat("Training Mean Squared Error (MSE):", mse_value, "\n")
cat("Training Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Training Mean Absolute Error (MAE):", mae_value, "\n")
df.stepwise = tidy(summary(model_stepwise))
df.stepwise
df.stepwise.significant = filter(df.stepwise, p.value < 0.05)
df.stepwise.significant
stepwise.predict = predict(model_stepwise, data.frame(listings[4,]), interval = "predict")
stepwise.predict
plot(model_stepwise)
#This one is LASSO
#Getting train and test splits
y_train = data_train$price
y_test = data_test$price
X_train = model.matrix(price ~ ., data = data_train)[, -8]#8th column is price
X_test = model.matrix(price ~ ., data = data_test)[, -8]
# Perform Lasso regression with cross-validation to select the lambda parameter
cv.lasso = cv.glmnet(X_train, y_train, alpha = 1)
# Fit the final Lasso model with the selected lambda using the training data
lasso_model = glmnet(X_train, y_train, alpha = 1, lambda = cv.lasso$lambda.min)
# Predict on the test data
predictions = predict(lasso_model, s = cv.lasso$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
coefficients(lasso_model)
# for LASSO
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
# Perform Ridge regression with cross-validation to select the lambda parameter
cv.ridge = cv.glmnet(X_train, y_train, alpha = 0)
# Fit the final Ridge model with the selected lambda using the training data
ridge_model = glmnet(X_train, y_train, alpha = 0, lambda = cv.ridge$lambda.min)
# Predict on the test data
predictions = predict(ridge_model, s = cv.ridge$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
coefficients(ridge_model)
# for Ridge
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
# Perform Elastic Net regression with cross-validation to select the lambda parameter
cv.en = cv.glmnet(X_train, y_train, alpha = 0.5)
# Fit the final Elastic Net model with the selected lambda using the training data
en_model = glmnet(X_train, y_train, alpha = 0.5, lambda = cv.en$lambda.min)
# Predict on the test data
predictions = predict(en_model, s = cv.en$lambda.min, newx = X_test)
# Evaluate the model on the test data (e.g., calculate RMSE, MSE, MAE)
rmse_value = sqrt(mean((predictions - y_test)^2))
mse_value = mean((predictions - y_test)^2)
mae_value = mean(abs(predictions - y_test))
# Print the evaluation metrics
cat("Testing Mean Squared Error (MSE):", mse_value, "\n")
cat("Testing Root Mean Squared Error (RMSE):", rmse_value, "\n")
cat("Testing Mean Absolute Error (MAE):", mae_value, "\n")
coefficients(en_model)
# for Elastic Net
# Calculate residuals
residuals = y_test-predictions
# Normality of Residuals
# Q-Q Plot
qqnorm(residuals)
qqline(residuals)
# Homoscedasticity of Residuals
# Scatterplot of Residuals vs. Fitted Values
plot(predictions, residuals, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")
citation('ggplot2')
citation('dplyr')
citation('glmnet')
citation('caret')
citation('Metrics')
model_step <- step(cancer.pred.only.interactions, direction = "both")
model_step <- step(cancer.pred.only.interactions, direction = "both")
summary(model_step)
summary(model_step)
summary(model_step)
formula(model_step)
newFormula = as.formula(substituteDirect(formula(model_step), as.list(coef(model_step))))
newFormula
as.formula(
paste0("y ~ ", round(coefficients(model_step)[1],2), "",
paste(sprintf(" %+.2f*%s ",
coefficients(model_step)[-1],
names(coefficients(model_step)[-1])),
collapse="")
)
)
rounded_coefficients <- round(coefficients(model_step), 6)  # Round coefficients to 6 digits
# Construct the formula with rounded coefficients
formula_str <- paste0("y ~ ",
round(rounded_coefficients[1], 6),
"",
paste(sprintf(" %+.6f*%s ",
rounded_coefficients[-1],
names(rounded_coefficients[-1])),
collapse="")
)
# Convert the formula string into a formula object
formula_with_rounded_coefficients <- as.formula(formula_str)
# Print the formula
print(formula_with_rounded_coefficients)
cancer.lm <- lm(CANCER_CrudePrev ~ ., data = cancer.pred.only)
summary(cancer.lm)
#removing ACCESS2_CrudePrev since not statistically significant
cancer.reduced <- lm(CANCER_CrudePrev ~ BPMED_CrudePrev + CHECKUP_CrudePrev + CHOLSCREEN_CrudePrev + COLON_SCREEN_CrudePrev + COREM_CrudePrev + COREW_CrudePrev  + DENTAL_CrudePrev + PAPTEST_CrudePrev + TEETHLOST_CrudePrev, data = df.unhealthy.precitors)
summary(cancer.reduced)
anova(cancer.lm, cancer.reduced)
cancer.interactions <- lm(CANCER_CrudePrev ~ (BPMED_CrudePrev + CHECKUP_CrudePrev + CHOLSCREEN_CrudePrev + COLON_SCREEN_CrudePrev + COREM_CrudePrev + COREW_CrudePrev  + DENTAL_CrudePrev + PAPTEST_CrudePrev + TEETHLOST_CrudePrev)^2, data = df.unhealthy.precitors)
summary(cancer.interactions)
library(olsrr)
df = read.csv('https://raw.githubusercontent.com/ethan2411/Data-603-604/main/500_Cities__Census_Tract-level_Data__GIS_Friendly_Format___2019_release_20231106.csv')
head(df)
#removing all data but the "prevalence" measures for calculations.
#df.calcs = df frame used for calculations.
df.calcs <- subset(df, select =- c(StateAbbr, PlaceName, PlaceFIPS, TractFIPS,Place_TractID,Population2010, ACCESS2_Crude95CI, ARTHRITIS_Crude95CI, BINGE_Crude95CI, BPHIGH_Crude95CI, BPMED_Crude95CI, CANCER_Crude95CI, CASTHMA_Crude95CI, CHD_Crude95CI, CHECKUP_Crude95CI, CHOLSCREEN_Crude95CI, COLON_SCREEN_Crude95CI,COPD_Crude95CI, COREM_Crude95CI, COREW_Crude95CI, CSMOKING_Crude95CI, DENTAL_Crude95CI,DIABETES_Crude95CI,  HIGHCHOL_Crude95CI, KIDNEY_Crude95CI, LPA_Crude95CI, MAMMOUSE_Crude95CI, MHLTH_Crude95CI, OBESITY_Crude95CI, PAPTEST_Crude95CI, PHLTH_Crude95CI, SLEEP_Crude95CI, STROKE_Crude95CI, TEETHLOST_Crude95CI, Geolocation))
head(df.calcs)
#narrowing the factors to only be unhealthy habits and preventative measures
df.unhealthy.precitors <- df.calcs <- subset(df.calcs, select =- c(ARTHRITIS_CrudePrev, BPHIGH_CrudePrev, CASTHMA_CrudePrev, CHD_CrudePrev, COPD_CrudePrev, DIABETES_CrudePrev, HIGHCHOL_CrudePrev, KIDNEY_CrudePrev, MAMMOUSE_CrudePrev, MHLTH_CrudePrev, PHLTH_CrudePrev, STROKE_CrudePrev))
head(df.unhealthy.precitors)
#narrowing the dataset even further to just predictive variables
cancer.pred.only <- subset(df.unhealthy.precitors,  select =- c(BINGE_CrudePrev, CSMOKING_CrudePrev, LPA_CrudePrev, OBESITY_CrudePrev, SLEEP_CrudePrev))
head(cancer.pred.only)
cancer.lm <- lm(CANCER_CrudePrev ~ ., data = cancer.pred.only)
summary(cancer.lm)
#removing ACCESS2_CrudePrev since not statistically significant
cancer.reduced <- lm(CANCER_CrudePrev ~ BPMED_CrudePrev + CHECKUP_CrudePrev + CHOLSCREEN_CrudePrev + COLON_SCREEN_CrudePrev + COREM_CrudePrev + COREW_CrudePrev  + DENTAL_CrudePrev + PAPTEST_CrudePrev + TEETHLOST_CrudePrev, data = df.unhealthy.precitors)
summary(cancer.reduced)
anova(cancer.lm, cancer.reduced)
cancer.interactions <- lm(CANCER_CrudePrev ~ (BPMED_CrudePrev + CHECKUP_CrudePrev + CHOLSCREEN_CrudePrev + COLON_SCREEN_CrudePrev + COREM_CrudePrev + COREW_CrudePrev  + DENTAL_CrudePrev + PAPTEST_CrudePrev + TEETHLOST_CrudePrev)^2, data = df.unhealthy.precitors)
summary(cancer.interactions)
model_step <- step(cancer.pred.only.interactions, direction = "both")
summary(model_step)
summary(model_step)
formula(model_step)
as.formula(
paste0("y ~ ", round(coefficients(model_step)[1],2), "",
paste(sprintf(" %+.2f*%s ",
coefficients(model_step)[-1],
names(coefficients(model_step)[-1])),
collapse="")
)
)
rounded_coefficients <- round(coefficients(model_step), 6)  # Round coefficients to 6 digits
# Construct the formula with rounded coefficients
formula_str <- paste0("y ~ ",
round(rounded_coefficients[1], 6),
"",
paste(sprintf(" %+.6f*%s ",
rounded_coefficients[-1],
names(rounded_coefficients[-1])),
collapse="")
)
# Convert the formula string into a formula object
formula_with_rounded_coefficients <- as.formula(formula_str)
# Print the formula
print(formula_with_rounded_coefficients)
summary(model_step)
#linearity assumption
library(ggplot2)
ggplot(model_step, aes(x=.fitted, y=.resid)) +
geom_point() + geom_smooth()+
geom_hline(yintercept = 0)
plot(model_step)
library(MASS)
bc = boxcox(model_step,lambda=seq(-1,1))
plot(cancer.reduced)
plot(cancer.reduced)
?VIF
VIF(lm(CANCER_CrudePrev ~ BPMED_CrudePrev + CHECKUP_CrudePrev + CHOLSCREEN_CrudePrev + COLON_SCREEN_CrudePrev + COREM_CrudePrev + COREW_CrudePrev  + DENTAL_CrudePrev + PAPTEST_CrudePrev + TEETHLOST_CrudePrev, data = df.unhealthy.precitors))
pairs(cancer.reduced)
pairs(cancer.pred.only)
model_step <- step(cancer.pred.only.interactions, direction = "both")
summary(model_step)
library(MASS)
bc = boxcox(model_step,lambda=seq(-1,1))
bc
summary(bc)
?boxcox
which.max(boxcox(bc^y))
which.max(boxcox(bc$y))
which.max((bc$y))
bc$x[which.max((bc$y))]
lambda = bc$x[which.max((bc$y))]
cancer.pred.only %>%
mutate(CANCER_boxcox = (CANCER_CrudePrev^lambda - 1)/lambda)
cancer.pred.new = cancer.pred.only %>%
mutate(CANCER_boxcox = (CANCER_CrudePrev^lambda - 1)/lambda)
library(MASS)
bc = boxcox(model_step,lambda=seq(-1,1))
cancer.pred.new = cancer.pred.only %>%
mutate(CANCER_boxcox = (CANCER_CrudePrev^lambda - 1)/lambda)
head(cancer.pred.new)
lm(formula = CANCER_boxcox ~ BPMED_CrudePrev + CHECKUP_CrudePrev +
CHOLSCREEN_CrudePrev + COLON_SCREEN_CrudePrev + COREM_CrudePrev +
COREW_CrudePrev + DENTAL_CrudePrev + PAPTEST_CrudePrev +
TEETHLOST_CrudePrev + BPMED_CrudePrev:CHECKUP_CrudePrev +
BPMED_CrudePrev:CHOLSCREEN_CrudePrev + BPMED_CrudePrev:COLON_SCREEN_CrudePrev +
BPMED_CrudePrev:COREM_CrudePrev + BPMED_CrudePrev:COREW_CrudePrev +
BPMED_CrudePrev:PAPTEST_CrudePrev + BPMED_CrudePrev:TEETHLOST_CrudePrev +
CHECKUP_CrudePrev:CHOLSCREEN_CrudePrev + CHECKUP_CrudePrev:COLON_SCREEN_CrudePrev +
CHECKUP_CrudePrev:COREM_CrudePrev + CHECKUP_CrudePrev:DENTAL_CrudePrev +
CHECKUP_CrudePrev:PAPTEST_CrudePrev + CHECKUP_CrudePrev:TEETHLOST_CrudePrev +
CHOLSCREEN_CrudePrev:COLON_SCREEN_CrudePrev + CHOLSCREEN_CrudePrev:COREM_CrudePrev +
CHOLSCREEN_CrudePrev:COREW_CrudePrev + CHOLSCREEN_CrudePrev:DENTAL_CrudePrev +
CHOLSCREEN_CrudePrev:PAPTEST_CrudePrev + CHOLSCREEN_CrudePrev:TEETHLOST_CrudePrev +
COLON_SCREEN_CrudePrev:COREW_CrudePrev + COLON_SCREEN_CrudePrev:DENTAL_CrudePrev +
COLON_SCREEN_CrudePrev:PAPTEST_CrudePrev + COLON_SCREEN_CrudePrev:TEETHLOST_CrudePrev +
COREM_CrudePrev:COREW_CrudePrev + COREM_CrudePrev:DENTAL_CrudePrev +
COREM_CrudePrev:PAPTEST_CrudePrev + COREW_CrudePrev:DENTAL_CrudePrev +
COREW_CrudePrev:PAPTEST_CrudePrev + COREW_CrudePrev:TEETHLOST_CrudePrev +
DENTAL_CrudePrev:PAPTEST_CrudePrev + DENTAL_CrudePrev:TEETHLOST_CrudePrev +
PAPTEST_CrudePrev:TEETHLOST_CrudePrev, data = cancer.pred.new)
new = lm(formula = CANCER_boxcox ~ BPMED_CrudePrev + CHECKUP_CrudePrev +
CHOLSCREEN_CrudePrev + COLON_SCREEN_CrudePrev + COREM_CrudePrev +
COREW_CrudePrev + DENTAL_CrudePrev + PAPTEST_CrudePrev +
TEETHLOST_CrudePrev + BPMED_CrudePrev:CHECKUP_CrudePrev +
BPMED_CrudePrev:CHOLSCREEN_CrudePrev + BPMED_CrudePrev:COLON_SCREEN_CrudePrev +
BPMED_CrudePrev:COREM_CrudePrev + BPMED_CrudePrev:COREW_CrudePrev +
BPMED_CrudePrev:PAPTEST_CrudePrev + BPMED_CrudePrev:TEETHLOST_CrudePrev +
CHECKUP_CrudePrev:CHOLSCREEN_CrudePrev + CHECKUP_CrudePrev:COLON_SCREEN_CrudePrev +
CHECKUP_CrudePrev:COREM_CrudePrev + CHECKUP_CrudePrev:DENTAL_CrudePrev +
CHECKUP_CrudePrev:PAPTEST_CrudePrev + CHECKUP_CrudePrev:TEETHLOST_CrudePrev +
CHOLSCREEN_CrudePrev:COLON_SCREEN_CrudePrev + CHOLSCREEN_CrudePrev:COREM_CrudePrev +
CHOLSCREEN_CrudePrev:COREW_CrudePrev + CHOLSCREEN_CrudePrev:DENTAL_CrudePrev +
CHOLSCREEN_CrudePrev:PAPTEST_CrudePrev + CHOLSCREEN_CrudePrev:TEETHLOST_CrudePrev +
COLON_SCREEN_CrudePrev:COREW_CrudePrev + COLON_SCREEN_CrudePrev:DENTAL_CrudePrev +
COLON_SCREEN_CrudePrev:PAPTEST_CrudePrev + COLON_SCREEN_CrudePrev:TEETHLOST_CrudePrev +
COREM_CrudePrev:COREW_CrudePrev + COREM_CrudePrev:DENTAL_CrudePrev +
COREM_CrudePrev:PAPTEST_CrudePrev + COREW_CrudePrev:DENTAL_CrudePrev +
COREW_CrudePrev:PAPTEST_CrudePrev + COREW_CrudePrev:TEETHLOST_CrudePrev +
DENTAL_CrudePrev:PAPTEST_CrudePrev + DENTAL_CrudePrev:TEETHLOST_CrudePrev +
PAPTEST_CrudePrev:TEETHLOST_CrudePrev, data = cancer.pred.new)
plot(new)
